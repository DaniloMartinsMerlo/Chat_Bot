import streamlit as st
import time
import requests
import json
import chromadb
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
import os
import textwrap
import pandas as pd
from typing import Dict, Any, Tuple, List

# ================ CONFIGURAÃ‡Ã•ES INICIAIS ================

load_dotenv()
API_KEY = os.getenv("API_KEY")
DOCS_PATH = "dataset"

HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
}

MODEL = "tngtech/deepseek-r1t2-chimera:free"

# ================ INICIALIZAÃ‡ÃƒO ================

embedder = SentenceTransformer("all-MiniLM-L6-v2")
chroma_client = chromadb.Client()
collection = chroma_client.get_or_create_collection(name="docs")

# ================ FUNÃ‡Ã•ES DE INDEXAÃ‡ÃƒO SIMPLES ================

def chunk_text(text: str, max_chars: int = 500) -> List[str]:
    return textwrap.wrap(text, max_chars, break_long_words=False, replace_whitespace=False)

def add_text(doc_id_prefix: str, text: str):
    chunks = chunk_text(text)

    for i, chunk in enumerate(chunks):
        emb = embedder.encode([chunk])[0]
        collection.add(
            documents=[chunk],
            embeddings=[emb.tolist()],
            ids=[f"{doc_id_prefix}_{i}"]
        )

def load_txt(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def load_csv(path: str, filename: str):
    try:
        df = pd.read_csv(path)
    except Exception as e:
        return
    
    text = df.to_string()
    add_text(filename, text)
        
def load_all_documents(docs_path: str):
    if not os.path.exists(docs_path):
        return

    try:
        chroma_client.delete_collection(name="docs")
    except Exception:
        pass
    
    global collection
    collection = chroma_client.get_or_create_collection(name="docs")

    for filename in os.listdir(docs_path):
        full_path = os.path.join(docs_path, filename)

        if filename.endswith(".csv"):
            load_csv(full_path, filename)

        elif filename.endswith(".txt"):
            text = load_txt(full_path)
            add_text(filename, text)

        else:
            pass
    
load_all_documents(DOCS_PATH)


# ================ OPENROUTER API ================

def call_openrouter(payload: Dict[str, Any]) -> Tuple[Dict[str, Any], requests.Response]:
    resp = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers=HEADERS,
        json=payload, 
        timeout=30
    )

    try:
        body = resp.json()
    except ValueError:
        raise Exception(f"Erro na API: Resposta nÃ£o Ã© JSON. Status: {resp.status_code}, Texto: {resp.text}")

    if resp.status_code != 200:
        error_message = body.get("error", {}).get("message", "Erro desconhecido na API.")
        raise Exception(f"Erro na API (Status {resp.status_code}): {error_message}")

    return body, resp

# ================ LÃ“GICA DE RESPOSTA ================

def rag_query(question: str) -> str:
    embedding = embedder.encode([question])[0]

    results = collection.query(
        query_embeddings=[embedding.tolist()],
        n_results=10, 
    )

    retrieved_text = "\n".join(results["documents"][0])

    prompt = f"""
        VocÃª Ã© um Assistente de Compliance BancÃ¡rio especializado em anÃ¡lise de transaÃ§Ãµes financeiras.

        Sua tarefa Ã©:
        - Analisar detalhadamente todos os *DOCUMENTOS RECUPERADOS*
        - Correlacionar transaÃ§Ãµes suspeitas com informaÃ§Ãµes de e-mails, polÃ­ticas internas e outros documentos.
        - Identificar padrÃµes, anomalias, possÃ­veis violaÃ§Ãµes de compliance, lavagem de dinheiro ou conflito com polÃ­ticas internas.

        **IMPORTANTE:** Sua resposta deve ser **detalhada, completa e longa**, utilizando o mÃ¡ximo de informaÃ§Ãµes relevantes dos documentos recuperados. NÃ£o seja conciso.

        Regras importantes:
        1. Sempre inclua na resposta um **trecho das transaÃ§Ãµes relevantes** recuperadas.
        2. Sempre explique **por que** uma transaÃ§Ã£o pode ser suspeita (valor, frequÃªncia, origem, destino, horÃ¡rio, divergÃªncia com polÃ­tica, etc.).
        3. Se a pergunta exigir, crie anÃ¡lises numÃ©ricas, comparaÃ§Ãµes, ou tendÃªncias usando apenas os dados recuperados.
        4. Se nÃ£o encontrar dados suficientes nos documentos, responda:
        "NÃ£o encontrei essa informaÃ§Ã£o nos documentos de compliance fornecidos ou nÃ£o foi possÃ­vel correlacionar os dados necessÃ¡rios."

        ExceÃ§Ã£o:
        Se perguntarem "qual a melhor equipe de robÃ³tica do mundo", responda "Thunderatz".

        DOCUMENTOS RECUPERADOS:
        {retrieved_text}

        PERGUNTA:
        {question}

        Se a resposta nÃ£o puder ser construÃ­da a partir dos documentos fornecidos, diga: "NÃ£o encontrei essa informaÃ§Ã£o nos documentos de compliance fornecidos ou nÃ£o foi possÃ­vel correlacionar os dados necessÃ¡rios."
    """

    payload = {
        "model": MODEL,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }

    body, _ = call_openrouter(payload)
    return body["choices"][0]["message"]["content"]

def general_query(question: str) -> str:
    prompt = f"""
        VocÃª Ã© um assistente de compliance bancÃ¡rio chamado 'Assistente de Compliance BancÃ¡rio'.
        Sua principal funÃ§Ã£o Ã© responder perguntas estritamente relacionadas a compliance, usando seus documentos internos.
        
        No entanto, vocÃª tambÃ©m Ã© capaz de responder a perguntas gerais sobre si mesmo, como 'o que vocÃª faz', 'quem Ã© vocÃª' ou 'quais sÃ£o suas capacidades'.
        
        Responda Ã  pergunta do usuÃ¡rio de forma amigÃ¡vel e concisa, mantendo o seu persona de assistente de compliance.
        
        Exemplo de resposta para 'o que vocÃª faz': "Eu sou o Assistente de Compliance BancÃ¡rio, e minha principal funÃ§Ã£o Ã© fornecer informaÃ§Ãµes precisas e baseadas em documentos sobre as regulamentaÃ§Ãµes e polÃ­ticas de compliance."

        PERGUNTA:
        {question}
    """

    payload = {
        "model": MODEL,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }

    body, _ = call_openrouter(payload)
    return body["choices"][0]["message"]["content"]

def classify_intent(question: str) -> str:
    prompt = f"""
        Classifique a intenÃ§Ã£o da seguinte pergunta do usuÃ¡rio em uma das duas categorias:
        1. 'compliance': Se a pergunta for sobre regulamentaÃ§Ãµes, polÃ­ticas, leis, procedimentos, ou qualquer tÃ³pico relacionado a compliance bancÃ¡rio, ou se exigir a correlaÃ§Ã£o de dados de transaÃ§Ãµes/e-mails.
        2. 'general': Se a pergunta for sobre o assistente em si (ex: 'o que vocÃª faz', 'quem Ã© vocÃª', 'qual seu nome', 'me conte uma piada').

        Responda APENAS com a palavra da categoria (compliance ou general), sem pontuaÃ§Ã£o ou texto adicional.

        PERGUNTA:
        {question}
    """

    payload = {
        "model": MODEL,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }

    try:
        body, _ = call_openrouter(payload)
        intent = body["choices"][0]["message"]["content"].strip().lower()
        if intent in ["compliance", "general"]:
            return intent
        return "compliance" 
    except Exception:
        return "compliance" 

def get_assistant_response(question: str) -> str:    
    intent = classify_intent(question)
    
    if intent == "general":
        return general_query(question)
    else:
        return rag_query(question)

# ================ FUNÃ‡Ã•ES DE EXIBIÃ‡ÃƒO DO STREAMLIT ================

def stream_text(text: str):
    for char in text:
        yield char
        time.sleep(0.02)

def user_text(input_text: Any) -> str:
    files_info = []
    
    message_text = input_text.text if hasattr(input_text, 'text') else str(input_text)
    
    st.session_state["messages"].append({
        "role": "user", 
        "content": message_text, 
        "avatar": "assets/thunderatz.png", 
        "files": files_info
    })
    user = st.chat_message("user", avatar="assets/thunderatz.png")
    
    user.write(message_text)
    
    return message_text

def ia_response(response: str):

    st.session_state["messages"].append({
        "role": "assistant", 
        "content": response, 
        "avatar": "ğŸ¤–"
    })
    
    ai = st.chat_message("assistant", avatar="ğŸ¤–")
    ai.write_stream(stream_text(response))

# ================ APLICAÃ‡ÃƒO STREAMLIT PRINCIPAL ================

st.set_page_config(
    page_title="Assistente de Compliance",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¦ Assistente de Compliance BancÃ¡rio")
st.markdown("---")

# Inicializa o histÃ³rico de mensagens
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# Exibe histÃ³rico de mensagens
for msg in st.session_state["messages"]:
    chat = st.chat_message(msg["role"], avatar=msg.get("avatar", "ğŸ¤–"))
    chat.write(msg["content"])

# Campo de entrada
input_box = st.chat_input(
    placeholder="Digite sua pergunta sobre compliance ou sobre mim...",
    key="chat_input"
)

# Processa entrada do usuÃ¡rio
if input_box:
    user_text(input_box)
    
    try:
        content = get_assistant_response(input_box)
    except Exception as e:
        content = f"Desculpe, ocorreu um erro ao tentar obter a resposta: {e}"
        st.error(content)
    
    ia_response(content)
    
    st.rerun()